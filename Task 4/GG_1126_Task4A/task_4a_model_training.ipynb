{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vP3r8fbCKfjM",
        "outputId": "c8902ada-f327-4d0b-8b25-d8d96c367e66"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNJn-DyZwyNl"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from PIL import Image\n",
        "imsize=50\n",
        "base_model = keras.applications.VGG19(\n",
        "    weights='imagenet',\n",
        "    input_shape=(imsize, imsize, 3),\n",
        "    include_top= False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tdLQyXgwyNp"
      },
      "source": [
        "## Freeze Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICOmxZD7wyNq"
      },
      "outputs": [],
      "source": [
        "# Freeze base model\n",
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRKnWxGOwyNq"
      },
      "source": [
        "## Add Layers to Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "befwRaP56UbA"
      },
      "outputs": [],
      "source": [
        "# Create inputs with correct shape\n",
        "inputs = keras.Input(shape=(imsize,imsize, 3))\n",
        "\n",
        "# Apply the base model to the inputs\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# Add pooling layer or flatten layer\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Add additional dense layers with dropout for regularization\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)  # Adding dropout for regularizationa\n",
        "\n",
        "x = keras.layers.Dense(128, activation='relu')(x)\n",
        "x = keras.layers.Dropout(0.1)(x)  # Adding dropout for regularizationa\n",
        "\n",
        "# x = keras.layers.Dense(64, activation='relu')(x)\n",
        "# x = keras.layers.Dropout(0.2)(x)  # Adding dropout for regularizationa\n",
        "\n",
        "# x = keras.layers.Dense(32, activation='relu')(x)\n",
        "# x = keras.layers.Dropout(0.1)(x)  # Adding dropout for regularization\n",
        "# Add final dense layer\n",
        "outputs = keras.layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "# Combine inputs and outputs to create the model\n",
        "model = keras.Model(inputs, outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqbbXZlhwyNr",
        "outputId": "9c16e213-6a57-429c-9b5a-3e11a174351a"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNiQ5jk5wyNs"
      },
      "source": [
        "## Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qur4mIJbwyNs"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss = 'categorical_crossentropy' , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnn6M3Z3wyNs"
      },
      "source": [
        "## Augment the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6baVbIKKfjQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Function to add random noise to an image 12 2929\n",
        "def add_noise(img):\n",
        "    noise = np.random.normal(loc=0, scale=12, size=img.shape)\n",
        "    img_with_noise = img + noise\n",
        "    img_with_noise = np.clip(img_with_noise, 0, 255)\n",
        "    return img_with_noise.astype(np.uint8)\n",
        "\n",
        "# Function to add pixelation to an image\n",
        "def add_pixelation(img):\n",
        "    pixelate = image.img_to_array(image.array_to_img(img).resize((29, 29), resample=image.NEAREST))\n",
        "    pixelate = image.img_to_array(image.array_to_img(pixelate).resize(img.shape[:-1], resample=image.NEAREST))\n",
        "    return pixelate.astype(np.uint8)\n",
        "\n",
        "# Custom ImageDataGenerator with noise and pixelation\n",
        "class CustomImageDataGenerator(ImageDataGenerator):\n",
        "    def random_transform(self, x, seed=None):\n",
        "        x = super().random_transform(x, seed)\n",
        "\n",
        "        # Add noise\n",
        "        x = add_noise(x)\n",
        "\n",
        "        # Add pixelation\n",
        "        x = add_pixelation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Create the generators\n",
        "datagen_train = CustomImageDataGenerator(\n",
        "    samplewise_center=True,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        ")\n",
        "\n",
        "datagen_valid = ImageDataGenerator(samplewise_center=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eik3xB-RwyNt"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1-F3KxswyNu",
        "outputId": "834e2c89-0fc3-4905-c9a4-84d4a996f559"
      },
      "outputs": [],
      "source": [
        "# load and iterate training dataset\n",
        "train_it = datagen_train.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/Rdataset/train/\",\n",
        "    target_size=(imsize, imsize),\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        ")\n",
        "# load and iterate validation dataset\n",
        "valid_it = datagen_valid.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/Rdataset/val/\",\n",
        "    target_size=(imsize, imsize),\n",
        "    color_mode=\"rgb\",\n",
        "    class_mode=\"categorical\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5V8enKnDwyNu"
      },
      "source": [
        "## Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asxaZYgswyNv",
        "outputId": "3a227743-a805-430d-e423-664f4f5281e9"
      },
      "outputs": [],
      "source": [
        "model.fit(train_it,\n",
        "          validation_data=valid_it,\n",
        "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
        "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
        "          epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2v6HqfOSwyNv"
      },
      "source": [
        "## Unfreeze Model for Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UltboKVwyNw"
      },
      "outputs": [],
      "source": [
        "# Unfreeze the base model\n",
        "base_model.trainable = True\n",
        "\n",
        "# Compile the model with a low learning rate\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = 0.00001),\n",
        "              loss = 'categorical_crossentropy' , metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK2xT6kVwyNw"
      },
      "outputs": [],
      "source": [
        "model.fit(train_it,\n",
        "          validation_data=valid_it,\n",
        "          steps_per_epoch=train_it.samples/train_it.batch_size,\n",
        "          validation_steps=valid_it.samples/valid_it.batch_size,\n",
        "          epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExsHmdyCwyNx"
      },
      "source": [
        "## Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STy63V-gwyNy"
      },
      "outputs": [],
      "source": [
        "model.evaluate(valid_it, steps=valid_it.samples/valid_it.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xumATRxpKfjR"
      },
      "outputs": [],
      "source": [
        "model.evaluate(train_it, steps=train_it.samples/train_it.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgNg0-RTEf47"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.preprocessing import image as image_utils\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "def show_image(image_path):\n",
        "    image = mpimg.imread(image_path)\n",
        "    plt.imshow(image)\n",
        "\n",
        "def make_predictions(image_path):\n",
        "    show_image(image_path)\n",
        "    image = image_utils.load_img(image_path, target_size=(50, 50))\n",
        "    image = image_utils.img_to_array(image)\n",
        "    image = image.reshape(1, 50, 50, 3)\n",
        "    image = preprocess_input(image)\n",
        "    preds = model.predict(image)\n",
        "\n",
        "    # Get class labels from the generator\n",
        "    class_labels = list(train_it.class_indices.keys())\n",
        "\n",
        "    # Get the predicted class index\n",
        "    predicted_class_index = tf.argmax(preds, axis=1).numpy()[0]\n",
        "\n",
        "    # Get the predicted class label\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "    return predicted_class_label\n",
        "\n",
        "# Assuming your validation images are in the 'dataset/val/' folder\n",
        "val_folder = 'events'\n",
        "\n",
        "# Get a list of all image files in the validation folder\n",
        "image_files = [f for f in os.listdir(val_folder) if f.endswith('.jpeg') or f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "# Loop through each image and make predictions\n",
        "for image_file in image_files:\n",
        "    image_path = os.path.join(val_folder, image_file)\n",
        "    predicted_label = make_predictions(image_path)\n",
        "    print(f\"Image: {image_file}, Predicted Label: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjTxeQKRKfjS"
      },
      "source": [
        "## Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oT1ltIH4_12"
      },
      "outputs": [],
      "source": [
        "# # save model\n",
        "# model.save('task4afinal.h5')\n",
        "# print('Model Saved!')\n",
        "\n",
        "# model.save_weights('task4afinal')\n",
        "# print('Weights Saved!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYmSgk8HKfjS"
      },
      "source": [
        "## Classification Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwC82FzAsDkF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image as image_utils\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Load the model architecture and weights\n",
        "loaded_model = load_model('task4afinal.h5')\n",
        "loaded_model.load_weights('task4afinal')\n",
        "\n",
        "def show_image(image):\n",
        "    if isinstance(image, str):  # Check if image is a file path\n",
        "        plt.imshow(plt.imread(image))\n",
        "    elif isinstance(image, np.ndarray):  # Check if image is a NumPy array\n",
        "        plt.imshow(image)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported image type\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def make_predictions_loaded_model(image):\n",
        "    show_image(image)\n",
        "\n",
        "    # Convert the image to RGB mode if it has an alpha channel\n",
        "    if image.shape[-1] == 4:\n",
        "        image = image[:, :, :3]\n",
        "\n",
        "    # Resize the image to the expected input size of the model\n",
        "    image = Image.fromarray(image.astype('uint8'))  # Ensure the image is in uint8 format\n",
        "    image = image.resize((imsize, imsize))\n",
        "\n",
        "    image = image_utils.img_to_array(image)\n",
        "    image = image.reshape(1, imsize, imsize, 3)\n",
        "    image = preprocess_input(image)\n",
        "    preds = model.predict(image)\n",
        "\n",
        "    # Get class labels from the generator\n",
        "    class_labels = [\"combat\", \"destroyedbuilding\", \"fire\", \"humanitarianaid\", \"militaryvehicles\"]\n",
        "\n",
        "    # Get the predicted class index\n",
        "    predicted_class_index = tf.argmax(preds, axis=1).numpy()[0]\n",
        "\n",
        "    # Get the predicted class label\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "    return predicted_class_label\n",
        "\n",
        "# Example usage with the loaded model\n",
        "image_path = 'event_4.png'\n",
        "image = plt.imread(image_path)  # Load the image directly\n",
        "predicted_label_loaded_model = make_predictions_loaded_model(image)\n",
        "print(\"Predicted Label using loaded model:\", predicted_label_loaded_model)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
